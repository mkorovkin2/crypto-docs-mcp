# Crypto Documentation MCP Server

A Model Context Protocol (MCP) server that provides blockchain developer documentation to AI coding agents like Claude Code and Cursor. Uses LLM-powered answer synthesis to deliver comprehensive responses with code examples, imports, and source citations. Supports multiple crypto projects including Mina Protocol, Solana, and Cosmos SDK.

## Features

- **LLM-Synthesized Answers**: Get comprehensive answers generated by GPT-4o, not just raw documentation chunks
- **Multi-Project Support**: Query documentation from Mina, Solana, Cosmos, and more
- **Hybrid Search**: Combines vector similarity (Qdrant) and full-text search (SQLite FTS5) with Reciprocal Rank Fusion
- **Smart Reranking**: Results are reranked using gpt-4o-mini for higher relevance
- **Working Code Examples**: Get complete, runnable code with imports and setup instructions
- **Error Debugging**: Explain errors with root cause analysis and fixes
- **Source Citations**: All answers include links to original documentation sources

## Supported Projects

| Project | Documentation | Source Code |
|---------|--------------|-------------|
| Mina Protocol | docs.minaprotocol.com | o1-labs/o1js |
| Solana | solana.com/docs | solana-labs/solana |
| Cosmos SDK | docs.cosmos.network | cosmos/cosmos-sdk |

Add more projects by creating a configuration file in `config/projects/`.

## Architecture

```
┌─────────────────┐     ┌──────────────────┐     ┌─────────────────┐
│  Document       │────▶│  Database Layer  │◀────│  MCP HTTP       │
│  Scraper        │     │  (Qdrant + FTS)  │     │  Server         │
└─────────────────┘     └──────────────────┘     └─────────────────┘
        │                       │                        │
        ▼                       │                        ▼
  Project Configs               ▼               ┌─────────────────┐
  (config/projects/)      Vector + SQLite      │  LLM Pipeline   │
                         (project-filtered)    │  (GPT-4o)       │
                                               └────────┬────────┘
                                                        ▼
                                               ┌─────────────────┐
                                               │  Coding Agents  │
                                               │  (Claude, etc.) │
                                               └─────────────────┘
```

**Data Flow:**
1. Scraper indexes documentation into Qdrant (vectors) and SQLite (full-text)
2. Server receives queries via MCP JSON-RPC over HTTP
3. Hybrid search retrieves relevant chunks with project filtering
4. Reranker (gpt-4o-mini) scores and ranks top results
5. LLM (GPT-4o) synthesizes comprehensive answer with citations

## Quick Start

### Prerequisites

- Node.js 18+
- Docker (for Qdrant vector database)
- OpenAI API key (for embeddings and LLM synthesis)

### 1. Install Dependencies

```bash
npm install
```

### 2. Configure Environment

```bash
cp .env.example .env
```

Edit `.env` and set your OpenAI API key:
```
OPENAI_API_KEY=sk-your-api-key-here
```

**Important:** Copy `.env` to each package directory (npm workspaces run from package directories):
```bash
cp .env packages/scraper/.env
cp .env packages/server/.env
```

### 3. Start Qdrant (Vector Database)

```bash
docker-compose up -d
```

Verify it's running:
```bash
curl http://localhost:6333/health
```

### 4. Build the Project

```bash
npm run build
```

### 5. Index Documentation

List available projects:
```bash
node packages/scraper/dist/index.js --list
```

Scrape a specific project:
```bash
# Index Mina Protocol docs
node packages/scraper/dist/index.js --project mina

# Index Solana docs
node packages/scraper/dist/index.js --project solana

# Index Cosmos SDK docs
node packages/scraper/dist/index.js --project cosmos
```

This will:
- Crawl the project's documentation site
- Parse and chunk the content
- Generate embeddings via OpenAI
- Store in Qdrant (vector) and SQLite (full-text) with project tags

**Note**: First run takes 5-10 minutes per project and costs ~$0.10-0.20 in OpenAI API calls.

### 6. Start the MCP Server

```bash
npm run server
```

The server runs at `http://localhost:3000` by default.

### 7. Test the Server

```bash
# Health check
curl http://localhost:3000/health

# List available tools
curl -X POST http://localhost:3000/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc":"2.0","method":"tools/list","id":1}'

# List available projects
curl -X POST http://localhost:3000/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc":"2.0","method":"tools/call","params":{"name":"list_projects","arguments":{}},"id":2}'

# Ask a question (LLM-synthesized answer)
curl -X POST http://localhost:3000/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc":"2.0","method":"tools/call","params":{"name":"ask_docs","arguments":{"question":"How do I create a smart contract?","project":"mina"}},"id":3}'
```

## Available MCP Tools

The server exposes 5 LLM-powered tools via the MCP protocol. All tools (except `list_projects`) require a `project` parameter.

| Tool | Description | Example Arguments |
|------|-------------|-------------------|
| `list_projects` | List available documentation projects | `{}` |
| `ask_docs` | Ask a question, get a synthesized answer with citations | `{"question": "How do state channels work?", "project": "mina"}` |
| `get_working_example` | Get complete, runnable code for a task | `{"task": "deploy a smart contract", "project": "solana"}` |
| `explain_error` | Debug an error with root cause and fixes | `{"error": "proof verification failed", "project": "mina", "context": "during zkApp deployment"}` |
| `search_docs` | Search raw documentation chunks (no LLM synthesis) | `{"query": "IBC protocol", "project": "cosmos", "limit": 5}` |

### Tool Details

#### `ask_docs`
Returns a comprehensive answer synthesized by GPT-4o, including:
- Direct answer to the question
- Relevant code snippets with imports
- Step-by-step instructions when applicable
- Source URLs for further reading

#### `get_working_example`
Returns production-ready code including:
- All necessary imports
- Complete implementation
- Setup/configuration instructions
- Usage example

#### `explain_error`
Returns debugging assistance including:
- What the error means
- Common causes
- Step-by-step fix instructions
- Prevention tips

#### `search_docs`
Returns raw documentation chunks for cases where you need:
- Direct access to source material
- Multiple perspectives on a topic
- Content type filtering (prose, code, api_reference)

## Adding New Projects

Create a new JSON file in `config/projects/`:

```json
{
  "id": "myproject",
  "name": "My Project",
  "docs": {
    "baseUrl": "https://docs.myproject.com",
    "excludePatterns": ["/api/", "/changelog/"],
    "maxPages": 200
  },
  "github": {
    "repo": "org/myproject",
    "branch": "main",
    "include": ["src/**/*.ts"],
    "exclude": ["**/*.test.ts"]
  },
  "crawler": {
    "concurrency": 5,
    "delayMs": 500
  }
}
```

Then run the scraper:
```bash
node packages/scraper/dist/index.js --project myproject
```

## Integration with AI Coding Agents

### Claude Desktop

Add to `~/Library/Application Support/Claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "crypto-docs": {
      "url": "http://localhost:3000/mcp",
      "transport": "http"
    }
  }
}
```

### Cursor

Configure MCP in Cursor settings with the HTTP endpoint:
```
http://localhost:3000/mcp
```

### Claude Code CLI

The server works with any MCP-compatible client via the HTTP endpoint.

## Project Structure

```
crypto-docs-mcp/
├── config/
│   └── projects/         # Project configuration files
│       ├── mina.json
│       ├── solana.json
│       └── cosmos.json
├── packages/
│   ├── shared/           # Types, DB clients, search logic
│   │   ├── src/
│   │   │   ├── config/   # Project config loading
│   │   │   ├── db/       # Qdrant & SQLite clients
│   │   │   ├── types.ts  # Shared TypeScript types
│   │   │   ├── search.ts # Hybrid search with RRF
│   │   │   ├── reranker.ts # GPT-4o-mini reranking
│   │   │   ├── llm.ts    # GPT-4o answer synthesis
│   │   │   └── embeddings.ts
│   │   └── package.json
│   ├── scraper/          # Documentation crawler
│   │   ├── src/
│   │   │   ├── crawler.ts
│   │   │   ├── parser.ts
│   │   │   ├── chunker.ts
│   │   │   ├── github-source.ts
│   │   │   └── index.ts
│   │   └── package.json
│   └── server/           # MCP HTTP server
│       ├── src/
│       │   ├── tools/    # MCP tool implementations
│       │   │   ├── ask-docs.ts
│       │   │   ├── working-example.ts
│       │   │   ├── explain-error.ts
│       │   │   ├── search-docs.ts
│       │   │   └── list-projects.ts
│       │   ├── prompts/  # LLM system prompts
│       │   ├── resources/
│       │   ├── transport.ts
│       │   └── index.ts
│       └── package.json
├── scripts/              # Demo and test scripts
│   ├── demo.ts
│   ├── demo.sh
│   └── test-integration.ts
├── data/                 # SQLite database storage
├── docker-compose.yml    # Qdrant setup
└── package.json          # Monorepo root
```

## Development

```bash
# Build all packages
npm run build

# Clean build artifacts
npm run clean

# List available projects
node packages/scraper/dist/index.js --list

# Index a project
node packages/scraper/dist/index.js --project mina

# Start server (production)
npm run server

# Start server in dev mode (with watch)
npm run dev:server
```

### Demo Scripts

Test the server with interactive demos:

```bash
# TypeScript demo (compiles first)
npm run demo

# Quick demo (pre-compiled)
npm run demo:quick

# Bash demo (shell script)
npm run demo:bash

# Or run directly with a specific project
./scripts/demo.sh solana
```

### Integration Tests

Run the integration test suite:

```bash
# Requires server to be running
npm run test:integration
```

Tests cover: health check, MCP initialization, all 5 tools, and resources.

## Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `OPENAI_API_KEY` | (required) | OpenAI API key for embeddings and LLM |
| `MCP_PORT` | 3000 | Server port |
| `MCP_HOST` | localhost | Server host |
| `QDRANT_URL` | http://localhost:6333 | Qdrant URL |
| `QDRANT_COLLECTION` | crypto_docs | Qdrant collection name |
| `SQLITE_PATH` | ./data/crypto_docs.db | SQLite database path |
| `LLM_MODEL` | gpt-4o | OpenAI model for answer synthesis |
| `LLM_MAX_TOKENS` | 4000 | Maximum tokens for LLM responses |
| `LLM_TEMPERATURE` | 0.3 | LLM temperature (lower = more focused) |
| `GITHUB_TOKEN` | (optional) | GitHub token for higher API rate limits |

## How It Works

1. **Project Config** defines documentation URL, GitHub repo, and crawler settings
2. **Scraper** crawls the documentation site for a specific project
3. **Parser** converts HTML to structured chunks (prose, code, API reference)
4. **GitHub Source** fetches and parses source code (TypeScript, Rust, Go)
5. **Chunker** splits large content with semantic overlap
6. **Embeddings** are generated via OpenAI text-embedding-3-small
7. **Qdrant** stores vectors for semantic search (with project tags)
8. **SQLite FTS5** provides fast full-text search (with project filtering)
9. **Hybrid Search** combines both using Reciprocal Rank Fusion
10. **Reranker** (gpt-4o-mini) scores top candidates for relevance
11. **LLM** (GPT-4o) synthesizes comprehensive answers with citations
12. **MCP Server** exposes tools via JSON-RPC over HTTP

## API Reference

### HTTP Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check with version info |
| `/mcp` | POST | MCP JSON-RPC 2.0 endpoint |
| `/mcp/events` | GET | Server-Sent Events (SSE) stream |

### Health Response

```json
{
  "status": "ok",
  "server": "crypto-docs-mcp",
  "version": "2.0.0",
  "features": ["llm-synthesis", "reranking"],
  "endpoints": {
    "mcp": "/mcp",
    "health": "/health"
  }
}
```

### MCP Methods

| Method | Description |
|--------|-------------|
| `initialize` | Initialize MCP connection |
| `tools/list` | List available tools |
| `tools/call` | Execute a tool |
| `resources/list` | List available resources |
| `resources/read` | Read a resource by URI |
| `ping` | Connection keepalive |

## Troubleshooting

### Qdrant Connection Failed
```bash
# Make sure Docker is running
docker-compose up -d

# Check Qdrant health
curl http://localhost:6333/health
```

### Empty Search Results
Run the scraper first to index documentation:
```bash
node packages/scraper/dist/index.js --project mina
```

### OpenAI API Errors
Verify your API key is set correctly in `.env`:
```bash
echo $OPENAI_API_KEY
```

### "OPENAI_API_KEY environment variable is required"
The `.env` file must be present in the package directory being run. Copy it to both:
```bash
cp .env packages/scraper/.env
cp .env packages/server/.env
```

### "No projects configured"
Make sure project JSON files exist in `config/projects/` directory.

### LLM Synthesis Too Slow
- Reduce `LLM_MAX_TOKENS` for shorter responses
- Increase `LLM_TEMPERATURE` for faster (but less focused) generation
- Use `search_docs` tool for raw results without LLM processing

## License

MIT

## Resources

- [Model Context Protocol](https://modelcontextprotocol.io)
- [Mina Protocol Documentation](https://docs.minaprotocol.com)
- [Solana Documentation](https://solana.com/docs)
- [Cosmos SDK Documentation](https://docs.cosmos.network)
